{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder,CrossValidator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define user rating columns :\n",
    "user_rating = ['userId', 'movieId', 'rating']\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation_Module\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read data from JSON file into a PySpark DataFrame :\n",
    "movie_ratings_spark = spark.read.json('movies.json')\n",
    "\n",
    "# Select relevant columns from the DataFrame :\n",
    "movie_ratings_spark = movie_ratings_spark.select(user_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   244|      1|     4|\n",
      "|   298|      1|     5|\n",
      "|   253|      1|     5|\n",
      "|   305|      1|     5|\n",
      "|     6|      1|     4|\n",
      "|    62|      1|     2|\n",
      "|   286|      1|     4|\n",
      "|   200|      1|     5|\n",
      "|   210|      1|     5|\n",
      "|   303|      1|     5|\n",
      "|   194|      1|     4|\n",
      "|   291|      1|     5|\n",
      "|   234|      1|     3|\n",
      "|   299|      1|     3|\n",
      "|   308|      1|     4|\n",
      "|    95|      1|     5|\n",
      "|    38|      1|     5|\n",
      "|   102|      1|     3|\n",
      "|    63|      1|     3|\n",
      "|   160|      1|     4|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the ALS model\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [5, 10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Define the cross-validator\n",
    "cross_validator = CrossValidator(estimator=als,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=evaluator,\n",
    "                                 numFolds=5)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(training, test) = movie_ratings_spark.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Fit the cross-validator to the training data\n",
    "cv_model = cross_validator.fit(training)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = cv_model.transform(test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Get the best model from cross-validation\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Generate top movie recommendations for all users using the best model\n",
    "userRecs = best_model.recommendForAllUsers(10)\n",
    "\n",
    "# Show the top recommendations for the first user\n",
    "# userRecs.select(\"user_id\", \"recommendations.movie_id\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set :\n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "############################### crose valedation ############################\n",
    "# Define the parameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [5, 10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Define the cross-validator\n",
    "cross_validator = CrossValidator(estimator=als,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=evaluator,\n",
    "                                 numFolds=5)\n",
    "\n",
    "(training, test) = movie_ratings_spark.randomSplit([0.8, 0.2])\n",
    "\n",
    "model = cross_validator.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   392|    463|     3| 3.6991503|\n",
      "|   897|    496|     5| 4.3330564|\n",
      "|   251|    148|     2| 2.5000026|\n",
      "|   251|    471|     3| 3.8907123|\n",
      "|   458|    496|     3| 3.7506993|\n",
      "|   883|    496|     2| 3.7914562|\n",
      "|   588|    463|     4| 2.8509839|\n",
      "|   588|    496|     3| 4.1895394|\n",
      "|   796|    496|     5| 4.4519105|\n",
      "|   101|    471|     3| 3.5822284|\n",
      "|   115|    471|     2| 3.1278152|\n",
      "|   385|    496|     2| 2.6508143|\n",
      "|   577|    471|     3| 3.8977022|\n",
      "|    44|    496|     4|  3.802884|\n",
      "|   606|    833|     5|  3.122258|\n",
      "|   236|    148|     4|  2.853957|\n",
      "|   738|    496|     4|  4.125635|\n",
      "|   663|    148|     4| 3.3692496|\n",
      "|   222|    471|     3|  3.668528|\n",
      "|   875|    496|     4| 3.7526584|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE): 1.0884023264591982\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the Root Mean Squared Error (RMSE) on the test data :\n",
    "predictions = model.transform(test)\n",
    "\n",
    "predictions.show()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definer user id : \n",
    "test_user_id = 1\n",
    "\n",
    "data = {\"user_id\": [test_user_id]}\n",
    "\n",
    "# Generate top movie recommendations for the specified user :\n",
    "user_recommendations = model.recommendForUserSubset(spark.createDataFrame(data), 10)\n",
    "\n",
    "# Display the recommendations for the specified user :\n",
    "user_recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ALS model :\n",
    "model_path = \"./best_model\"\n",
    "\n",
    "# Save the model :\n",
    "model.write().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Load The Module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    55|      7|     3|\n",
      "|    55|     22|     5|\n",
      "|    55|     50|     4|\n",
      "|    55|     56|     4|\n",
      "|    55|     79|     5|\n",
      "|    55|     89|     5|\n",
      "|    55|    117|     3|\n",
      "|    55|    118|     5|\n",
      "|    55|    121|     3|\n",
      "|    55|    144|     5|\n",
      "|    55|    174|     4|\n",
      "|    55|    181|     4|\n",
      "|    55|    254|     2|\n",
      "|    55|    257|     3|\n",
      "|    55|    273|     5|\n",
      "|    55|    405|     1|\n",
      "|    55|    597|     2|\n",
      "|    55|    678|     3|\n",
      "|    55|    685|     1|\n",
      "|    55|   1016|     1|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ModelUsage\").getOrCreate()\n",
    "\n",
    "# Specify the path where the ALS model is saved\n",
    "model_path = \"./best_model\"\n",
    "\n",
    "# Load the ALS model\n",
    "loaded_model = ALSModel.load(model_path)\n",
    "\n",
    "user_id = 55\n",
    "selected_user_df = movie_ratings_spark.filter(col('userId') == user_id)\n",
    "\n",
    "selected_user_df.show()\n",
    "\n",
    "# user_recommendations = model.recommendForUserSubset(selected_user_df, 5)\n",
    "# user_recommendations.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1.08701507564806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\BigDataSetup\\Spark\\spark-3.2.4-bin-hadoop2.7\\python\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                              |\n",
      "+------+---------------------------------------------------------------------------------------------+\n",
      "|55    |[{1311, 15.909463}, {884, 14.893386}, {1245, 14.099055}, {1084, 13.582125}, {865, 12.662319}]|\n",
      "+------+---------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "import pandas as pd\n",
    "\n",
    "# Define user rating columns :\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation_Module\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "user_rating = ['userId', 'movieId', 'rating']\n",
    "# Read data from JSON file into a PySpark DataFrame :\n",
    "movie_ratings_spark = spark.read.json('movies.json')\n",
    "\n",
    "# Select relevant columns from the DataFrame :\n",
    "movie_ratings_spark = movie_ratings_spark.select(user_rating)\n",
    "\n",
    "# Create test and train set :\n",
    "(training, test) = movie_ratings_spark.randomSplit([0.8, 0.2])\n",
    "                                             \n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the Root Mean Squared Error (RMSE) on the test data :\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "user_id = 55\n",
    "selected_user_df = movie_ratings_spark.filter(col('userId') == user_id)\n",
    "\n",
    "user_recommendations = model.recommendForUserSubset(selected_user_df, 5)\n",
    "user_recommendations.show(truncate=False)\n",
    "\n",
    "model_path = \"./best_model\"\n",
    "\n",
    "# Save the model\n",
    "model.write().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "model_path= 'C:/Users/Youcode/Desktop/Devlepeure Data/Project_Breif/film-recommender_with_ia/ALS/best_model'\n",
    "\n",
    "# Load the ALS model :\n",
    "loaded_model = ALSModel.load(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
